{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0654f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports here\n",
    "import os, csv, threading, multiprocessing, time, random, itertools, math\n",
    "from ListingScraper import ListingScraper\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f2b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_words = set()\n",
    "\n",
    "def start_scrape(urls, savePath):\n",
    "    listings = ListingScraper()\n",
    "    for url in urls:\n",
    "        listings.fetch_data(url, savePath)\n",
    "\n",
    "def random_words(num_words, used_words=set()):\n",
    "    # load a list of English words\n",
    "    with open('words.txt', 'r') as f:\n",
    "        words = [line.strip() for line in f]\n",
    "\n",
    "    if len(used_words) == len(words):\n",
    "        raise Exception(\"All words have been used\")\n",
    "\n",
    "    # choose num_words random words from the list\n",
    "    random_words = []\n",
    "    for i in range(num_words):\n",
    "        # choose a random word from the list\n",
    "        word = random.choice(words)\n",
    "\n",
    "        # check if the word has already been used\n",
    "        if word in used_words:\n",
    "            # if it has, generate a new word until we find one that hasn't been used\n",
    "            while word in used_words:\n",
    "                word = random.choice(words)\n",
    "        else:\n",
    "            # if it hasn't been used, add it to the set of used words\n",
    "            used_words.add(word)\n",
    "\n",
    "        random_words.append(word)\n",
    "\n",
    "    return random_words\n",
    "\n",
    "def to_url(word):\n",
    "    return f\"https://www.facebook.com/marketplace/106246092739961/search?query={word}\"\n",
    "\n",
    "def random_urls(url_count: int):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    urls = []\n",
    "\n",
    "    looping = math.ceil(math.log(url_count,len(alphabet)))\n",
    "\n",
    "    for i in range(looping):\n",
    "        for word in itertools.product(alphabet, repeat=i+1):\n",
    "            urls.append(to_url(''.join(word)))\n",
    "            if len(urls) == url_count:\n",
    "                return urls\n",
    "\n",
    "def thread_urls(threads, per_thread: int):\n",
    "    words_count = per_thread * threads\n",
    "    urls = random_urls(words_count)\n",
    "\n",
    "    # Create a list of lists to store the split URLs\n",
    "    split_urls = [[] for _ in range(threads)]\n",
    "\n",
    "    # Iterate over the URLs and assign them to the appropriate list in split_urls\n",
    "    for i, url in enumerate(urls):\n",
    "        split_urls[i % threads].append(url)\n",
    "\n",
    "    return split_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = '../../Desktop/Uni/Year3-Project/CSV_Files/All_Listings/Links'\n",
    "url = \"https://www.facebook.com/marketplace/\"\n",
    "threads_used = 1\n",
    "words_count = 10000\n",
    "\n",
    "paths = [basePath+f\"{i}.csv\" for i in range(threads_used)]\n",
    "\n",
    "urls_lists = [random_urls(words_count) for i in range(threads_used)]\n",
    "\n",
    "urls2 = thread_urls(threads_used,words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8441daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (start_scrape):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zorko\\anaconda3\\envs\\bs4\\lib\\threading.py\", line 1009, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\zorko\\anaconda3\\envs\\bs4\\lib\\threading.py\", line 946, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\zorko\\AppData\\Local\\Temp\\ipykernel_27812\\3256174749.py\", line 6, in start_scrape\n",
      "  File \"C:\\Users\\zorko\\Python\\mrktplc_scraper\\Scrapers.py\", line 66, in fetch_data\n",
      "    while self.__driver.current_url != url and attempts != 2:\n",
      "  File \"C:\\Users\\zorko\\anaconda3\\envs\\bs4\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 530, in current_url\n",
      "    return self.execute(Command.GET_CURRENT_URL)[\"value\"]\n",
      "  File \"C:\\Users\\zorko\\anaconda3\\envs\\bs4\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 440, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\zorko\\anaconda3\\envs\\bs4\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 245, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=109.0.5414.74)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x0055F243]\n",
      "\t(No symbol) [0x004E7FD1]\n",
      "\t(No symbol) [0x003DD04D]\n",
      "\t(No symbol) [0x003C2D7A]\n",
      "\t(No symbol) [0x0042BE7B]\n",
      "\t(No symbol) [0x0043C196]\n",
      "\t(No symbol) [0x00428386]\n",
      "\t(No symbol) [0x0040163C]\n",
      "\t(No symbol) [0x0040269D]\n",
      "\tGetHandleVerifier [0x007F9A22+2655074]\n",
      "\tGetHandleVerifier [0x007ECA24+2601828]\n",
      "\tGetHandleVerifier [0x00608C0A+619850]\n",
      "\tGetHandleVerifier [0x00607830+614768]\n",
      "\t(No symbol) [0x004F05FC]\n",
      "\t(No symbol) [0x004F5968]\n",
      "\t(No symbol) [0x004F5A55]\n",
      "\t(No symbol) [0x0050051B]\n",
      "\tBaseThreadInitThunk [0x75157D69+25]\n",
      "\tRtlInitializeExceptionChain [0x7748BB9B+107]\n",
      "\tRtlClearBits [0x7748BB1F+191]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "for i in range(threads_used):\n",
    "    threads.append(threading.Thread(target=start_scrape, args=(urls_lists[i],paths[i])))\n",
    "\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e224f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "daf8ec14243273134b0a49a9958b9a813df1225fe55e6942c3723e1ef6b4aa3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
